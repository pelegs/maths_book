\section{Sequences and series}
\subsection{Basics}
A \emph{sequence} is an indexed collection of \emph{elements}. By \textit{indexed} we mean that the order of the elements in a sequence matters (unlike with sets): changing the order of any element changes the sequence as a whole. The following are some examples of sequences composed of real numbers:
\begin{itemize}
	\item $1,-3,0,-7,2,1.5,4,0,1,-0.35,\sqrt{2}$.
	\item $0,1,2,1,1,-1,0$.
	\item $1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \frac{1}{5}, \frac{1}{6}, \dots$
	\item $0,1,0,1,0,1,0,1,0,1,0,1,0,1,\dots$
\end{itemize}
The examples above present two more properties of sequences:
\begin{itemize}
	\item Elements may repeat (unlike in the case of sets), and
	\item sequences can be either \emph{finite} (as in the first two examples), or \emph{infinite} (as in the latter two examples).
\end{itemize}

The number of elements in a sequence is called its \emph{length}. In the case of infinite sequences we say that their length equals $\infty$ (infinity). The elements of a sequence $a$ are usually indexed using a subscript, such that $a_{1}$ is the first element in the sequence, $a_{2}$ is the second element in the sequence, etc. - and generally $a_{i}$ is the $i$-th element in the sequence, where $i\in\mathbb{N}$.

We can therefore define a sequence somewhat more formally as a function from a subset of the natural numbers to the real numbers:
\begin{equation}
	a:N\to\Rs,
\end{equation}
where $N\subseteq\mathbb{N}$.
\begin{example}{Sequences as functions}{}
	The following $9$-element sequence $a$
	\begin{center}
		\begin{tikzpicture}
			\matrix[matrix of math nodes, nodes={anchor=center, minimum width=13mm}, row 1/.style={nodes={font=\large}}] (seq)
			{3, & 4, & \frac{1}{2}, & 0, & 2, & 6, & -\frac{2}{3}, & 0, & -1.\\};
			\foreach \k in {1,...,9}{
				\node[xred, below of=seq-1-\k] (a-\k) {$a(\k)$};
				\draw[xred, -stealth] (a-\k) -- (seq-1-\k);
			}
		\end{tikzpicture}
	\end{center}
	
	can be viewed as a function
	\[
		a:\left\{1,2,\dots,9\right\}\to\Rs,
	\]
	or more precisely as a function
	\[
		a:\left\{1,2,\dots,9\right\}\to\left\{-1,-\frac{2}{3},0,\frac{1}{2},2,3,4,6\right\}.
	\]

	\vspace{2em}
	The follow infinite sequence $b$
	\begin{center}
		\begin{tikzpicture}
			\matrix[matrix of math nodes, nodes={anchor=center, minimum width=13mm}, row 1/.style={nodes={font=\large}}] (seq)
			{1, & \frac{1}{2}, & \frac{1}{3}, & \frac{1}{4}, &  \frac{1}{5}, & \frac{1}{6}, & \frac{1}{7}, & \dots \\};
			\foreach \k in {1,...,7}{
				\node[xpurple, below of=seq-1-\k] (a-\k) {$b(\k)$};
				\draw[xpurple, -stealth] (a-\k) -- (seq-1-\k);
			}
		\end{tikzpicture}
	\end{center}
	can be viewed as a function
	\[
		b:\mathbb{N}\to(0,1].
	\]
\end{example}

Since sequences can be viewed as functions, they can be defined using formulas: for example, the sequence
\[
	1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \dots
\]
can be defined using the simple formula
\[
	a_{n}=\frac{1}{n}.
\]

\begin{example}{Some sequences defined using formulas}{}
	\renewcommand*{\arraystretch}{3}
	\centering
	\begin{tabular}{rll}
		$(-1)^{n}$ & $\Rightarrow$ & $-1,1,-1,1,-1,1,-1,1,-1,\dots$\\
		$3n+4$ & $\Rightarrow$ & $7,10,13,16,19,22,\dots$\\
		$(n+1)^{2}$ & $\Rightarrow$ & $4,9,16,25,36,49,\dots$\\
		$\begin{cases}
			\colorbox{xred!20}{2n+1} & \text{if}\ n\text{ is odd},\\
			\colorbox{xblue!20}{n-1}  & \text{if}\ n\text{ is even}.
		\end{cases}$ & $\Rightarrow$ & $\colorbox{xred!20}{3},\colorbox{xblue!20}{1},\colorbox{xred!20}{7},\colorbox{xblue!20}{3},\colorbox{xred!20}{11},\colorbox{xblue!20}{5},\colorbox{xred!20}{15},\colorbox{xblue!20}{7}, \dots$\\
	\end{tabular}
\end{example}

Sequences can also be defined using \emph{recursion}, where the value of an element is defined using previous values and a \emph{starting value}. For example:
\[
	a_{n} = a_{n-1}^{2}-2,
\]
with the starting value $a_{1}=3$. We the get that
\[
	a_{2} = a_{1}^{2}-2 = 3^{2}-2 = 7,
\]
and thus
\[
	a_{3} = a_{2}^{2}-2 = 7^{2}-2 = 47,
\]
etc.

\begin{example}{The Fibonacci sequence}{}
	The \emph{Fibonacci sequences} is a well-known sequence defined using the following recursive rule:
	\[
		F_{n} = F_{n-1} + F_{n-2},
	\]
	with $F_{1}=F_{2}=1$. The first few elements of the sequence are therefore
	\[
		1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,\dots
	\]
	See \autoref{fig:Fib_graphical} for a graphical representation of the Fibonacci sequence.

\end{example}

\begin{figure}
	\pgfmathsetmacro{\scale}{0.5}
	\pgfmathsetmacro{\helixscale}{28.34677*\scale} % Ratio of cm to bp
	\centering
	\begin{tikzpicture}[scale=\scale]
		\def\horizontal{{-1,-1,1,1}}
		\def\vertical{{1,-1,-1,1}}
		\def\center{{1,0}}
		\pgfmathsetmacro{\phi}{1.618033988749} % Golden ratio
		\pgfmathsetmacro{\x}{0}
		\pgfmathsetmacro{\y}{0}
		\foreach \n in {1,...,8}{
			% Calcs
			\pgfmathsetmacro{\k}{\n+1}
			\pgfmathsetmacro{\Fib}{int(ceil((\phi^(\k-1)-(\phi)^(-(\k-1)))/sqrt(5)))} % Fibonacci sequence
			\pgfmathsetmacro{\dx}{\Fib*\horizontal[mod(\n,4)]}
			\pgfmathsetmacro{\dy}{\Fib*\vertical[mod(\n,4)]}
			\pgfmathsetmacro{\dcx}{\center[mod(\n,2)]}
			\pgfmathsetmacro{\dcy}{\center[mod(\n+1,2)]}

			\coordinate (s) at (\x,\y);
			\coordinate (e) at ({\x+\dx},{\y+\dy});
			\coordinate (o) at ({\x+\dcx*\dx},{\y+\dcy*\dy}); % dx, dy, dx, dy, dx, dy, ...

			% Draw
			\pgfmathsetmacro{\m}{int(mod(\n,8))}
			\draw[thick, fill=xcol\m!20] (s) rectangle (e) node[midway, font=\tiny] {$\Fib$};
			\pic[draw, thick, angle radius=\helixscale*\Fib] {angle=s--o--e};

			% Re-calc
			\pgfmathparse{\x+\dx}
			\xdef\x{\pgfmathresult}
			\pgfmathparse{\y+\dy}
			\xdef\y{\pgfmathresult}
		}
	\end{tikzpicture}
	\caption{A graphical representation of the Fibonacci sequence: two squares of side $1$ are placed adjacent to each other on the plane. In each subsequent step a new square is place such that its side is equal to the combined sides of the previous two squares. This way, the side of each square in the sequence follows the Fibonacci sequence. In each square we draw a quarter circle centered on one of the vertices, such that we get the famous \emph{golden ratio} helix.}
	\label{fig:Fib_graphical}
\end{figure}

\begin{note}{Focus of section}{}
	From now on in the section we will focus on infinite sequences only.
\end{note}

\subsection{Types of sequences}%
\label{sub:Types of sequences}
Consider the sequence $a_{n}=n^{2}$. Since $n\in\mathbb{N}$, for any $n,\ a_{n+1} > a_{n}$, since $(n+1)^{2} > n^{2}$ (see \autoref{fig:n^2_seq}). We say that such a sequence is \emph{increasing}. In fact, for a sequence to be increasing some sequential elements can be equal: for example, the sequence $c_{n}=1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,\dots$ is also a increasing sequence. Thus, the definition of a increasing sequence is the following:

\begin{definition}{increasing sequence}
	A sequence $a_{n}$ is said to be \textit{increasing} if for any $n\in\mathbb{N},\ a_{n+1}\geq a_{n}$.
\end{definition}
If we change the condition to $a_{n+1}>a_{n}$ we say that such a sequence is \emph{strictly increasing}. In the above examples $a_{n}$ is a strictly increasing sequence, while $c_{n}$ is just increasing (since for some indeces $n,\ c_{n+1}=c_{n}$).

Similarly, a \emph{decreasing} sequence is a sequence $b_{n}$ for which for any $n\in\mathbb{N},\ b_{n+1}\leq b_{n}$. An example of such sequence is $b_{n}=\frac{1}{n}$ (see \autoref{fig:1/n_seq}). ANd of course, if we change the condition to $b_{n+1}<b_{n}$ then the sequence is \emph{strictly decreasing}.

Generally, a sequence that is either increasin or decreasing is said to be \emph{monotone}. If a sequence is monotone starting only from a certain $n$, we say that the sequence is \emph{eventually monotone} (i.e. \textit{eventually increasing} or \textit{eventually decreasing}). An example of such sequence is $d_{n}=(n-5)^{2}$ (\autoref{fig:(n-5)^2_seq}): for $N\in{1,2,3,4,5}$ it is decreasing, but starting from $n=5$ it is increasing for any $n$.

As an example of a sequence which isn't monote, consider the sequence $e_{n}=\sin(n)$: for some values of $n,\ e_{n+1}>e_{n}$ and for some other values $e_{n+1}<e_{n}$ (see \autoref{fig:sin(n)_seq}).

\pgfplotsset{
}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={20}{0}{400}{a_{n}=n^{2}},
		]
		\addplot[xred, only marks, mark=*] {x^2};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $a_{n}=n^{2}$ is increasing, and is in fact \textit{strictly} increasing.}
	\label{fig:n^2_seq}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={20}{0}{1.5}{b_{n}=\frac{1}{n}},
		]
		\addplot[xblue, only marks, mark=*] {1/x};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $b_{n}=\frac{1}{n}$ is decreasing, and is in fact \textit{strictly} decreasing.}
	\label{fig:1/n_seq}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={20}{0}{250}{d_{n}=(x-5)^{2}},
		]
		\addplot[xpurple, only marks, mark=*] {(x-5)^2};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $d_{n}=(n-5)^{2}$ starts as a decreasing sequence, but starting from $n=5$ it is increasing, making it an \textit{eventually increasing sequence}.}
	\label{fig:(n-5)^2_seq}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={20}{-1.1}{1.1}{e_{n}=\sin(n)},
		]
		\addplot[black!20, dashed, samples=150] {sin(deg(x))};
		\addplot[xorange, only marks, mark=*] {sin(deg(x))};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $e_{n}=\sin(n)$ is neither increasing nor decreasing. For reference, the function $\sin(x)$ is plotted as a dashed line behind $e_{n}$.}
	\label{fig:sin(n)_seq}
\end{figure}

The following are two ways to determine whether a sequence $a_{n}$ is monotone:
\begin{descitemize}
	\item[Difference test] if $a_{n+1}-a_{n}\geq0$ for all $n\in\mathbb{N}$, then the sequence is increasing. If $a_{n+1}-a_{n}\leq0$ for all $n\in\mathbb{N}$ then the sequence is decreasing.
	\item[Ratio test] if $\frac{a_{n}+1}{a_{n}}\geq1$ for all $n\in\mathbb{N}$ then the sequence is increasing, and if $\frac{a_{n+1}}{a_{n}}<1$ for all $n\in\mathbb{N}$ then the sequence is decreasing.
\end{descitemize}

\begin{example}{Difference test}{}
	Given the sequence $a_{n}=\frac{n}{n+1}$, we look at the difference $a_{n+1}-a_{n}$:
	\begin{align*}
		a_{n+1}-a_{n} &= \frac{n+1}{n+2}-\frac{n}{n+1} = \frac{(n+1)(n+1)-(n+2)n}{(n+1)(n+2)}\\
					  &= \frac{n^{2}+2n+1-n^{2}-2n}{(n+1)(n+2)} = \frac{1}{(n+1)(n+2)} < 1\quad \forall n\in\mathbb{N}.
	\end{align*}
	The last (in)equality stems from the fact that no matter what $n$ we subtitute into $(n+1)(n+2)$, the result will be greater than $1$, and thus $\frac{1}{(n+1)(n+2)}$ is always smaller than $1$. Therefore, $a_{n}$ is a decreasing sequence.
\end{example}

\begin{example}{Ratio test}{}
	Given the sequence $b_{n}=\frac{2^{n}}{n^{2}}$, the ratio of $a_{n+1}$ to $a_{n}$ is
	\[
		\frac{a_{n+1}}{a_{n}} = \frac{\frac{2^{n+1}}{(n+1)^{2}}}{\frac{2^{n}}{n^{2}}} = 2\frac{n^{2}}{(n+1)^{2}}.
	\]
	Let's look at the first few approximated values of the ratio $\frac{n^{2}}{(n+1)^{2}}$:
	\begin{center}
		\begin{NiceTabular}{p{2mm}l}[
			cell-space-limits=3pt, code-before=\rowcolors{1}{\tabcol!15}{\tabcol!10} \rowcolor{\tabcol!50}{1}
			]
			\toprule
			\RowStyle{\bfseries} $n$ & $\frac{n^{2}}{(n+1)^{2}}$ \\
			\midrule
			0 & 0\\
			1 & 0.25\\
			2 & 0.44444\ldots\\
			3 & 0.5625\\
			4 & 0.64\\
			5 & 0.69444\ldots\\
			6 & 0.7346938775510204\\
			7 & 0.765625\\
			8 & 0.7901234567901234\\
			9 & 0.81\\
			10 & 0.8264462809917356\\
			11 & 0.840277777\ldots\\
			12 & 0.8520710059171598\\
			13 & 0.8622448979591837\\
			\bottomrule
		\end{NiceTabular}
	\end{center}
	We see that for any $n\geq3,\ \frac{n^{2}}{(n+1)^{2}}>\frac{1}{2}$, and therefore $2\frac{n^{2}}{(n+1)^{2}}>1$. Thus, the sequence is eventually increasing.
\end{example}

Some sequences are \emph{bounded} from below: this means that their elements never get smaller than some constant $\underline{M}\in\Rs$. For example, consider the simple sequence $a_{n}=n$, where $n=\left\{1,2,3,4,\dots\right\}$: there is no element in the sequence that is smaller than $1$. Therefore, $a_{n}$ is bounded from below by $1$. Of course, one may argue that $b_{n}$ is also bounded from below by $0$, or $-6$, or in fact any negative number. This is true, however we are usually interested in the \textit{maximal} number $\underline{M}$ that bounds the sequence from below, which in this case is $\underline{M}=1$. We call that number the \emph{infimum} of the sequence, and denote it as $\inf a_{n}$.

Similarly, a sequence $a_{n}$ can be bounded from above by some number $\overline{M}\in\Rs$, i.e. there exist no $n$ for which $a_{n}>\overline{M}$. We call the \textit{minimal} such number the \emph{supremum} of the sequence $a_{n}$, denoted $\sup a_{n}$. For example, the sequence $b_{n}=\frac{1}{n}$ is bounded from above by any real number $x\geq1$, and therefore $\sup b_{n}=1$. In fact, $b_{n}$ is also bounded from below by $\underline{M}=0$, and therefore we say that it is \emph{bounded}. Another example of a sequence that is bounded is $e_{n}=\sin(n)$, which is bounded from below by $\underline{M}=-1$ and from above by $\overline{M}=1$.

\begin{example}{Bounded and unbounded sequences}{}
	The following table shows some examples of sequences that are bounded from below, from above, or neither:

	\begin{center}
		\begin{NiceTabular}{llcc}[
			cell-space-limits=3pt, code-before=\rowcolors{1}{\tabcol!15}{\tabcol!10} \rowcolor{\tabcol!50}{1}
			]
			\toprule
			\RowStyle{\bfseries} $a_{n}$ & First 5 elements & $\inf a_{n}$ & $\sup a_{n}$\\
			\midrule
			$n^{2}-n$ & $0,2,6,12,20,\dots$ & $0$ & - \\
			$\frac{n}{n+1}$ & $\frac{1}{2},\frac{2}{3},\frac{3}{4},\frac{4}{5},\frac{5}{6},\dots$ & $\frac{1}{2}$ & $1$ \\
			$\eu^{-n}$ & $\eu^{-1},\eu^{-2},\eu^{-3},\eu^{-4},\eu^{-5},\ldots$ & $0$ & $\eu^{-1}$\\
			$\log(n)$ & $0,\log(2),\log(3),\log(4),\log(5),\dots$ & $0$ & - \\
			$(-1)^{n}$ & $-1,1,-1,1,-1,\dots$ & $-1$ & $1$\\
			$(-1)^{n}n$ & $-1,2,-3,4,-5,\ldots$ & - & - \\
			$(-2)^{n}$ & $-2,4,-8,16,-32,\dots$ & - & - \\
			\bottomrule
		\end{NiceTabular}
	\end{center}
\end{example}

\subsection{Subsequences}
Given any sequence $a_{n}$, we can remove from it any number of its elements (including $0$ elements) and get a new sequence $b_{n}$ which is a \emph{subsequence} of $a_{n}$. For example, let $a_{n}=n^{2}-5n$. We can remove each 2nd element from $a_{n}$ (i.e. those with indices $2,4,6,8,\ldots$) and get the following sequence $b_{n}$:

\begin{tikzpicture}[node distance=6mm]
	\node (a0) at (0,0) {$a_{n}=$};
	\foreach \n in {1,...,12}{
		\pgfmathsetmacro{\ai}{int(\n^2-5*\n)}
		\pgfmathsetmacro{\m}{int(\n-1)}
		\pgfmathsetmacro{\c}{int(mod(\n,2))}
		\ifnum \c=1
			\def\col{xred}
		\else
			\def\col{xblue}
		\fi
		\node[right of=a\m, element={\col!30}] (a\n) {$\ai$};
		\node[right of=a\n, anchor=north east, xshift=1pt] (comma) {$,$};
	}
	\node[right of=comma, xshift=-1mm] (dots1) {$\dots$};
	
	\node[below of=a0, yshift=-15mm] (b0) {$b_{n}=$};
	\foreach \n in {1,...,6}{
		\pgfmathsetmacro{\bi}{int((2*\n-1)^2-5*(2*\n-1))}
		\pgfmathsetmacro{\m}{int(\n-1)}
		\pgfmathsetmacro{\k}{int(2*\n-1)}
		\node[right of=b\m, element={xred!30}] (b\n) {$\bi$};
		\node[right of=b\n, anchor=north east, xshift=1pt] (comma) {$,$};
		\draw[-stealth] (a\k.south) to [out=-90, in=90, looseness=0.4] (b\n.north);
	}
	\node[right of=comma, xshift=-1mm] (dots2) {$\dots$};
\end{tikzpicture}

\begin{note}{Order of elements in a subsequence}{}
	A subsequence must preserve the order of the original sequence, since all we do in practice is removing elements from the original sequence, without changing the order of the remaining elements.
\end{note}

Let's look at a more formal defintion of a subsequence, which uses the choice of indices instead of removing elements:
\begin{definition}{Subsequence}{}
	A subsequence of a sequence $a_{n}$ is a sequence $a_{n_{k}}$, where $n_{k}$ is a \textbf{strictly increasing} sequence of natural numbers.
\end{definition}

To create a subsequence using the above defintion, one can first create a sequence of indices $n_{k}$, and then subtitute only those indices into $n$ in $a_{n}$. For example, given the sequence $a_{n}=n^{2}-5n$ from before, we can define a sequence of indices $n_{k}=1,3,5,7,9,11,\dots$ which would then yield the subsequence $b_{n}$ shown before.

The reason we define $n_{k}$ to be strictly increasing is to avoid changing the order of the elements from the original sequeunce $a_{n}$: for example, if we allowed $n_{k}$ to be ``just'' increasing, we might end up with a case where there are two subsequent equal indices, e.g. $n_{k}=1,3,5,8,9,9,10,\dots$. That would mean that we repeat an element from $a_{n}$ \textbf{twice or more} in the subsequence (in the example this would be $a_{9}$), rendering it invalid as a subsequence, since as mentioned before - a subsequence must perserve the order of the original sequence.

Subsequences share all of the above-mentioned properties of the original sequence: if the original sequence is increasing or decreasing - so do all of its subsequences, and if it is bounded from above or below - so do all of its subsequences. Let's prove two of these properties:

\begin{proof}{Rising sequences and their subsequences}{}
	\textbf{Claim}: given an \textbf{increasing} sequence $a_{n}$, all of its subsequences are also increasing sequences themselves.

	\vspace{1em}
	\textbf{Proof}: using contradiction. Let $a_{n}$ be an increasing sequence, and $b_{n}$ a subsequence of $a_{n}$ which isn't increasing. From the fact that $b_{n}$ is not an increasing sequence we know that there exist at least two indices $k,m$ such that $k<m$ but $b_{k}>b_{m}$. Since any $b_{n}$ is an element of $a_{n}$ without change of order, we can substitute $b_{k}=a_{i}$ for some index $i$ and $b_{m}=a_{j}$ for some index $j$, such that $i<j$ (since $k<m$ - this is exactly the idea of preserving the order of $a_{n}$). We therefore get that $a_{i}=b_{k}>b_{m}=a_{j}$, or simply $a_{i}>a_{j}$ even though $i<j$ - in contradiction to $a_{n}$ being an increasing sequence. Therefore there can be no subsequence of $a_{n}$ that isn't an increasing sequence.
\end{proof}

\begin{proof}{Bounded sequences and their subsequences}{}
	\textbf{Claim}: given a sequence $a_{n}$ which is \textbf{bounded from below}, all of its subsequences are also bounded from below.

	\vspace{1em}
	\textbf{Proof}: also using contradiction. Let $a_{n}$ be a sequence bounded from below by $\inf a_{n}=\underline{M}$. Let $b_{n}$ be a subsequence of $a_{n}$ that isn't bounded from below - i.e. there exist an element $b_{i}$ such that $b_{i}<\underline{M}$. Since $b_{n}$ is a subsequence of $a_{n}$, $b_{i}=a_{j}$ for some index $j$. Therefore $a_{j}=b_{i}<\underline{M}$ in contradiction to $\underline{M}$ being the infimum of $a_{n}$. Therefore, a subsequence of a sequence bounded from below can not be unbounded from below.
\end{proof}

\begin{challenge}{Further proofs}{}
	\begin{enumerate}
		\item Prove that all subsequences of a decreasing sequence are themselves decreasing.
		\item Prove that all subsequences of a sequence bounded from above are themselves bounded from above.
		\item Prove that all subsequences of a \textbf{strictly} increasing/decreasing sequence are themselves increasing or decreasing, respectively.
		\item Given a bounded sequence $a_{n}$ with $\inf a_{n}=\underline{M}$, can it have a subseqeunce $b_{n}$ with $\inf b_{n}\neq \underline{M}$? If yes - give an example. If no - prove your claim.
	\end{enumerate}
\end{challenge}

\subsection{Limits}
As you probably noticed by now, some infinite sequences seem to approach a certain value as we increase $n$. That is to say, the bigger $n$ is, the closer such a sequence $a_{n}$ gets to a certain value $L\in\Rs$. For example, the sequence $b_{n}=\frac{1}{n}$ approaches to $L=0$ as we increase $n$ (see again \autoref{fig:1/n_seq}). The sequence $a_{n}=\frac{1}{n^{2}+1}$ approaches the value $L=1$ as we increase $n$ (see \autoref{fig:1/n^2+1_seq}). On the contrary, the sequence $d_{n}=(n-5)^{2}$ eventually increase in such a way that it ``approaches'' $L=\infty$, while $e_{n}=\sin(n)$ doesn't approach any value and instead endlessly ``jumps'' around in a repeated manner.

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			vector plane,
			width=10cm, height=7cm,
			xmin=0, xmax=21,
			ymin=0, ymax=2,
			x axis line style={-stealth, thick},
			xlabel={$n$},
			ylabel={$a_{n}=\frac{1}{n^{2}}+1$},
			% xtick={1,...,20},
			ticklabel style={font=\small},
			domain={0:20},
			samples=21,
		]
		\addplot[xred, only marks, mark=*] {1/x^2+1};
		\addplot[thick, dashed] {1};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $a_{n}=\frac{1}{n^{2}}+1$ approaches the value $L=1$ as $n$ increases.}
	\label{fig:1/n^2+1_seq}
\end{figure}

The formal term for the behaviour of $a_{n}$ and $b_{n}$ is called \emph{convergence}, and it is one of the most important properties of infinite sequences. In this subsection we will define, analyze, and explain it in detail. To begin, we can divide all infinite sequences into two separate categories:
\begin{enumerate}
	\item Sequences which converge to a finite number $L\in\Rs$.
	\item Sequences which do not converge to any finite number.
\end{enumerate}

Sequences in the second category are said to be \emph{diverging}, and they can be further split into two separate categories:
\begin{enumerate}[label=\roman*.]
	\item Sequences which diverge to either positive or negative infinity.
	\item Sequences which neither converge nor diverge to $\pm\infty$.
\end{enumerate}

Let us start with a more precise analysis of sequences that diverge to $\pm\infty$. In essence, a sequence which diverges to positive infinity is a sequence that is bounded from below but not from above, that is - given any real number $R$ the sequence eventually passes it. In other words, all the elements in the suquence \textit{after a certain value of} $n$ are greater than $R$, for any $R$ that we choose.

Take for example the sequence $a_{n}=n^{2}$. It most certainly has a lower boundry, namely $\inf a_{n}=1$. On the other hand, given any $R\in\Rs$ eventually the values of $a_{n}$ pass it. For example, given $R=100$, the elements of $a_{n}$ pass it after just $10$ elements (since $a_{11}=11^{2}=121>100$). The number $R=1,000,000$ is passed after $1000$ elements, etc. No matter how big $R$ is, \textbf{eventually} $a_{n}$ will pass it. Therefore, we say that $a_{n}$ \textit{goes to infinity}, and denote it by writing
\begin{equation}
	\lim\limits_{n\to\infty}a_{n}=\infty.
	\label{eq:first_limit}
\end{equation}

The notation $\lim$ is short for \emph{limit}. While it can be argued that a divergent sequence has no limit, sometimes the term is used in the case of divergence to $\pm\infty$.

\begin{note}{Another limit notation}{}
	Another common notation used to denote that a sequence $a_{n}$ is going to infinity as $n$ increases is the following:
	\[
		a_{n} \xrightarrow[]{n\to\infty} \infty.
	\]
\end{note}

A more formal definition of this behaviour is as follows:
\begin{definition}{Sequence going to inifnity}{}
	Let $a_{n}$ be an infinite sequence. If for any $R\in\Rs$ there exist $n_{R}\in\mathbb{N}$ such that for any $n>n_{R},\ a_{n}>R$, the sequence is said to be going to positive infinity. We denote this fact by writing
\[
	\lim\limits_{n\to\infty}a_{n}=\infty.
\]
\end{definition}

\begin{note}{Chain of inequality}{}
	Note the following: say we have $5$ real numbers $k_{1},\dots,k_{5}$. If
	\[
		k_{1} > k_{2} > k_{3} = k_{4} \geq k_{5}.
	\]
	then we know that
	\[
		k_{1} > k_{5}.
	\]
	This might seem obvious - but is worth noting before we move on, as we will be using similar chains of inequalities in up-coming proofs.
\end{note}

Of course, for negative infinity the behaviour is very similar: a sequence $a_{n}$ with an upper boundry $\overline{M}$ and no lower bound $\underline{M}$ is said to be \emph{going to negative infinity}, since for any $R\in\Rs$ there exist an $n_{R}\in\mathbb{N}$ for which if $n>n_{R}$ then $a_{n}<R$.

Generally speaking, proving that a sequence goes to either positive or negative infinity follows a certain pattern, which we will examplify using the sequence $a_{n}=\frac{n}{2}$ (\autoref{fig:n/2_seq}). It should be clear that the sequence goes to positive infinity as $n$ increases, since we can make the values of $a_{n}$ as large as we want by substituting a respective $n$ into $\frac{n}{2}$: for example, given $R=1000$ we can subtitute $n=2000$, yielding $a_{2000}=\frac{2000}{2}=1000$, and thus any $a_{n}$ where $n>2000$ will be bigger than $R=1000$. For $R=1,000,000$ we can substitute $n=2,000,000$ and so forth.

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			vector plane,
			width=10cm, height=7cm,
			xmin=0, xmax=21,
			ymin=0, ymax=12,
			axis line style={-stealth, thick},
			xlabel={$n$},
			ylabel={$a_{n}=\frac{n}{2}$},
			ticklabel style={font=\small},
			domain={1:21},
			samples=20,
		]
		\addplot[xred, only marks, mark=*] {x/2};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $a_{n}=\frac{n}{2}$ goes to positive infinity as $n$ increases.}
	\label{fig:n/2_seq}
\end{figure}

To show that this is true for any $R\in\Rs$ we should do the following: given a real number $R$ find an index $n_{0}$ such that $a_{n_{0}}\geq R$. Since $a_{n}$ is a strictly increasing sequence, that would mean that for any $n>n_{0},\ a_{n}>a_{n_{0}}\geq R$, or simply $a_{n}>R$. In the case of $a_{n}=\frac{n}{2}$ we can simply choose the closest integer to $2R$ that is also bigger than $2R$ (i.e. if $R=2.3$ we choose $n_{0}=3$, if $R=100.7$ we choose $n_{0}=101$, etc.).

To always get an integer \textit{equal to or bigger than} $R$ we can use the \emph{ceiling} operator. For any given $x\in\Rs$, its ceiling (denoted $\ceil{x}$) is the closest integer which is bigger than or equal to $x$, or more formally:

\begin{definition}{Ceiling and floor operators}{}
	Let $x\in\Rs$. Then
	\begin{align}
		\ceil{x} &= \min\left(\left\{ n\in\mathbb{N} | n\geq x\right\}\right).\\
		\floor{x} &= \max\left(\left\{ n\in\mathbb{N} | n\leq x\right\}\right).
		\label{eq:ceiling}
	\end{align}
	i.e. - $\ceil{x}$ is the \textbf{minimal} integer $n$ that is \textbf{bigger than or equal} to $x$, and $\floor{x}$ is the \textbf{maximal} integer $n$ that is \textbf{smaller than or equal} to $x$.
\end{definition}

Using the value $n_{0}=\ceil{2R}$ we can show, step by step, that indeed $\lim\limits_{n\to\infty}=\infty$ by using several subtitutions: for any $n>n_{0}$ we get that

\vspace{1em}
\[
	a_{n} = \frac{n}{2} \tikzmark{gt}{>} \frac{n_{0}}{2} = \frac{\ceil{2R}}{2} \tikzmark{geq}{\geq}\frac{2R}{2} = R,
\]
\tikz[overlay, remember picture, node distance=1cm]{
	\node[xred, font=\smaller] (gttxt) at ($(pic cs:gt)+(0,1cm)$) {since $n>n_{0}$};
	\draw[-stealth, xred] ($(gttxt)+(3pt,-5pt)$) -- ($(pic cs:gt)+(3pt,9pt)$);
	\node[xblue, font=\smaller] (geqtxt) at ($(pic cs:geq)-(0,1cm)$) {since $\ceil{2R}\geq2R$};
	\draw[-stealth, xblue] ($(geqtxt)+(3pt,5pt)$) -- ($(pic cs:geq)+(3pt,-5pt)$);
}

\vspace{2em}
or simply $a_{n}>R$.

\vspace{2em}
\begin{example}{The sequence $\log(n)$}{}
	Let's show that the sequence $a_{n}=\log(n)$ (see graph below) goes to infinity as $n$ increases: first, we note that $\log(n)$ is a strictly increasing sequence bounded from below by $\underline{M}=0$. Now, given some positive $R\in\Rs$ we chose $n_{0}=\ceil{\eu^{R}}$ and thus get that for any $n>n_{0}$
	\[
		a_{n} > a_{n_{0}} = \log\left(n_{0}\right) = \log\left(\ceil{\eu^{R}}\right) \geq \log\left(\eu^{R}\right) = R.
	\]

	altogther we get $a_{n}>R$, and therefore $\lim\limits_{n\to\infty}\log(n)=\infty$.

	\vspace{2em}
	\begin{center}
		\begin{tikzpicture}[]
			\begin{axis}[
				sequence plot={50}{0}{6}{a_{n}=\log(n)},
				xtick={0,10,...,50},
			]
			\addplot[xred, only marks, mark=*] {ln(x)};
			\end{axis}
		\end{tikzpicture}
	\end{center}

	\textbf{Note}: this proof works because $\log(n)$ is a \textit{strictly} increasing sequence. If it were only an increasing sequence we would not be guaranteed that $n>n_{0}$ means that $a_{n}>a_{n_{0}}$, and the entire process would not yield that $\log(n)$ always passes any given real number $R$. Indeed, by naively looking at the graph above we may be mistaken to think that $\log(n)$ actually approaches some finite number, say $4.5$ or so, and doesn't go to infinity. This is of course not the case.
\end{example}

\begin{example}{A sequence which goes to negative infinity}{}
	Let us now show that the sequence $a_{n}=-\sqrt{n}$ goes to negative infinity. We first note that $-\sqrt{n}$ is always negative, is decreasing and bounded from above by $\overline{M}=0$. For any given negative $R\in\Rs$ we choose $n_{0}=\floor{R^{2}}$, and thus for any $n>n_{0}$ we get
	\[
		a_{n} < a_{n_{0}} = -\sqrt{n_{0}} = -\sqrt{\floor{R^{2}}} \leq -\sqrt{R^{2}} = -|R| = R.
	\]

	\tbw{is this example actually necessary? Yes reinforcement is fine-JS}
\end{example}

The next type of sequences we ananlyze are those sequences that converge to a real number $L$ as $n$ increases - i.e. as $n$ increases, the terms of the sequence get closer and closer to $L$. A classical example for such a sequence is $a_{n}=\frac{1}{n}$ (\autoref{fig:1/n_seq}): as $n$ increases, the terms $\frac{1}{n}$ become smaller and smaller (while always being positive) and the sequence as a whole approaches $L=0$.

Sequences don't have to approach a limit from above: some sequences approach a limit from below (\autoref{fig:logistic_seq}), while others may \emph{oscillate} around the limit (\autoref{fig:converging_cosine_seq}).

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={20}{0}{2}{a_{n}=\frac{1}{1+\exp(\frac{5-x}{4})}},
		]
		\addplot[xred, only marks, mark=*] {1/(1+e^(-0.25*(x-5)))};
		\addplot[thick, dashed] {1};
		\end{axis}
	\end{tikzpicture}
	\caption{The logistic sequence $a_{n}=\frac{1}{1+\exp(\frac{5-x}{4})}$ approaches the value $L=1$ from below as $n\to\infty$.}
	\label{fig:logistic_seq}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={71}{-4}{4}{a_{n}=\frac{\cos(n)}{10n}},
			xtick={0,10,...,70},
		]
		\addplot[thin, domain={2:71}] {cos(deg(x))/(0.1*x)};
		\addplot[xdarkgreen, only marks, mark=*] {cos(deg(x))/(0.1*x)};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $a_{n}=\frac{\cos(n)}{10n}$ approaches, with oscillations, the limit $L=0$. A line connecting the elements is drawn to help see the progression of the sequence.}
	\label{fig:converging_cosine_seq}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={50}{0}{1.1}{a_{n}=\exp{-2a_{n}}},
			xtick={0,10,...,50},
		]
		\addplot[xdarkblue!75!black, mark=*, mark options={xblue}] coordinates {
(1,1.00000)
(2,0.13534)
(3,0.76287)
(4,0.21746)
(5,0.64732)
(6,0.27400)
(7,0.57811)
(8,0.31468)
(9,0.53294)
(10,0.34443)
(11,0.50215)
(12,0.36630)
(13,0.48066)
(14,0.38239)
(15,0.46544)
(16,0.39421)
(17,0.45456)
(18,0.40288)
(19,0.44675)
(20,0.40922)
(21,0.44112)
(22,0.41386)
(23,0.43705)
(24,0.41724)
(25,0.43410)
(26,0.41970)
(27,0.43197)
(28,0.42150)
(29,0.43042)
(30,0.42281)
(31,0.42929)
(32,0.42376)
(33,0.42847)
(34,0.42446)
(35,0.42788)
(36,0.42496)
(37,0.42745)
(38,0.42533)
(39,0.42714)
(40,0.42559)
(41,0.42691)
(42,0.42579)
(43,0.42674)
(44,0.42593)
(45,0.42662)
(46,0.42603)
(47,0.42654)
(48,0.42610)
(49,0.42647)
(50,0.42616)
		};
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence defined by the recursive formula $a_{n+1}=\exp(-2a_{n})$ with $a_{1}=1$ converges to the limit $L\approx0.4263027510068627$, or more precisely $\frac{1}{2}W(2)$, where $W$ is the Lambert $W$ function.}
	\label{fig:convergent_recursive_seq}
\end{figure}

We define convergence in a similar way to how we defined that a sequence goes to $\infty$: in that case we had to show that for any $R\in\Rs$ the sequence eventually surpasses $R$ and no element is ever again equal to or smaller than $R$. In the case of convergence to some finite number $L\in\Rs$ we will show that for any distance $\varepsilon$ from $L$ - no matter how small! - the sequence eventually stays within $\varepsilon$ of $L$.

Let us use the simplest convergence example to explain this idea: $a_{n}=\frac{1}{n}$, which converges to $L=0$. Given a small number $\varepsilon$, say $\varepsilon=\frac{1}{10}$, eventually the sequence stays at most within $\frac{1}{10}$ of $L=0$. This happens starting from $n_{0}=10$: any element thereafter is smaller than $\frac{1}{10}$, which means that it is withing $\varepsilon=\frac{1}{10}$ of $L=0$ (see \autoref{fig:1/n_convergence}).

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={30}{-0.5}{1.2}{a_{n}=\frac{1}{n}},
			xtick={0,10,...,30},
			xticklabel style={yshift=-10pt},
			extra y ticks={-0.1,0,0.1},
			extra y tick labels={$-\varepsilon$, $L=0$, $\varepsilon$},
			y axis line style={stealth-stealth, thick},
		]
		\addplot[thick, name path=A] {0.1};
		\addplot[thick, name path=B] {-0.1};
		\addplot[xgreen, opacity=0.15] fill between[of=A and B];
		\addplot[xred, only marks, mark=*] {1/x};
		\draw[-stealth, very thick] (10,0.5) -- node[above, yshift=5mm] {$n=10$} (10,0.2);
		\end{axis}
	\end{tikzpicture}
	\caption{The sequence $a_{n}=\frac{1}{n}$. For any $n>10$, the element $a_{n}$ is withing $\varepsilon=\frac{1}{10}$ of the limit $L=0$. The interval $\left(-\varepsilon,\varepsilon\right)=\left(-\frac{1}{10},\frac{1}{10}\right)$ on the $y$-axis is highlighted in green.}
	\label{fig:1/n_convergence}
\end{figure}

\begin{figure}[]
	\centering
	\begin{tikzpicture}[]
		\begin{axis}[
			sequence plot={70}{-0.5}{1.2}{a_{n}=\frac{1}{n}},
			xtick={0,10,...,70},
			xticklabel style={yshift=-10pt},
			extra y ticks={-0.1,0,0.1},
			extra y tick labels={$-\varepsilon$, $L=0$, $\varepsilon$},
			y axis line style={stealth-stealth, thick},
		]
		\addplot[thick, name path=A] {0.05};
		\addplot[thick, name path=B] {-0.05};
		\addplot[xgreen, opacity=0.15] fill between[of=A and B];
		\addplot[xred, only marks, mark=*, mark options={scale=0.5}] {1/x};
		\draw[-stealth, very thick] (20,0.4) -- node[above, yshift=5mm] {$n=20$} (20,0.1);
		\end{axis}
	\end{tikzpicture}
	\caption{Same as \autoref{fig:1/n_convergence} except here $\varepsilon=0.05$, and thus $n_{0}=\ceil{\frac{1}{0.05}}=20$. Therefore, starting fom $n=20$ all the elements of the sequence are within the interval $(-0.05,0.05)$. Note: the values of the sequence are drawn with smaller filled circles to prevent overlap between subsequent points.}
	\label{fig:1/n_convergence2}
\end{figure}

We can repeat this for different value of $\varepsilon$: given $\varepsilon=\frac{1}{100}$, for any $n>100$ the elements $a_{n}$ are guaranteed to be within $\pm\frac{1}{100}$ of $L=0$. Given $\varepsilon=\frac{1}{5000}$, for any $n>5000$ the elements $a_{n}$ are within $\pm\frac{1}{5000}$ of $L=0$, etc. In general, given any real $\varepsilon$, no matter how small, we can set $n_{0}=\ceil{\frac{1}{\varepsilon}}$, and then for any $n>n_{0}$ we get that

\vspace{2em}
\begin{equation}
	a_{n} \tikzmark{st1}{\ <\ } a_{n_{0}} = \frac{1}{n_{0}} = \frac{1}{\ceil{\frac{1}{\varepsilon}}} \tikzmark{leq}{\ \leq\ } \frac{1}{\frac{1}{\varepsilon}} = \varepsilon,
\end{equation}
\tikz[overlay, remember picture, node distance=1cm]{
	\node[xred, font=\smaller] (st1txt) at ($(pic cs:st1)+(0,1cm)$) {since $a_{n}$ is strictly decreasing};
	\draw[-stealth, xred] ($(st1txt)+(5pt,-5pt)$) -- ($(pic cs:st1)+(5pt,9pt)$);
	\node[xblue, font=\smaller] (leqtxt) at ($(pic cs:leq)-(0,1cm)$) {since $\ceil{\frac{1}{x}}\geq\frac{1}{x}$};
	\draw[-stealth, xblue] ($(leqtxt)+(5pt,7pt)$) -- ($(pic cs:leq)+(5pt,-5pt)$);
}

\vspace{2em}
i.e. altogther
\begin{equation}
	a_{n} < \varepsilon,
\end{equation}
and therefore $a_{n}$ is within $\pm\varepsilon$ of $L=0$.

\begin{example}{Convergence}{}
	Let's prove that the sequence $a_{n}=\frac{n+1}{n^{2}}$ converges to $L=0$ as $n\to\infty$. For any $\varepsilon\in\Rs$ we chose $n_{0}=\ceil{\frac{\varepsilon}{2}}$. Since $a_{n}$ is a strictly decreasing sequence\footnote{Show that!}, we get that for any $n>n_{0}$:
	\[
		a_{n} < a_{n_{0}} = \frac{n_{0}+1}{n_{0}^{2}}.
	\]
	Note the following: for any $x>1,\ x^{3}>x>1$. Therefore if we replace both $n_{0}$ and $1$ in the numerator of the expression $\frac{n_{0}+1}{n_{0}^{2}}$ by $n_{0}^{3}$ we are guaranteed to get a number bigger than $\frac{n_{0}+1}{n_{0}^{2}}$. We can therefore continue with the substitution:
	\[
		\frac{n_{0}+1}{n_{0}^{2}} < \frac{n_{0}^{3}+n_{0}^{3}}{n_{0}^{2}} = \frac{2n_{0}^{3}}{n_{0}^{2}} = 2n_{0} = \cancel{2}\frac{\varepsilon}{\cancel{2}} = \varepsilon,
	\]
	and therefore altogther we get that
	\[
		a_{n} < \varepsilon,
	\]
	and thus $a_{n}$ converges to $L=0$ as $n$ increases to $\infty$.
\end{example}
